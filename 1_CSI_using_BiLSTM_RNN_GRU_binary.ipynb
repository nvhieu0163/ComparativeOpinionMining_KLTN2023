{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvhieu0163/ComparativeOpinionMining_KLTN2023/blob/main/1_CSI_using_BiLSTM_RNN_GRU_binary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y6iJv3Wugg_",
        "outputId": "19bc6509-8464-4406-f076-0eacceeedd8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py_vncorenlp\n",
            "  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius (from py_vncorenlp)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n",
            "  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4306 sha256=ce0d070af286ef5b058b3a57a2cb957a2c829fbe6e524d38f53cb489cf238d9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
            "Successfully built py_vncorenlp\n",
            "Installing collected packages: pyjnius, py_vncorenlp\n",
            "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install py_vncorenlp\n",
        "!pip install transformers\n",
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2yVyoOjvDrj"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjfsRcXdvaG-",
        "outputId": "3c9c250b-175a-4b5e-9d97-9a48b164fa12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsB78z9mvpJY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fom8tvbzvF5y"
      },
      "outputs": [],
      "source": [
        "import py_vncorenlp\n",
        "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/content/drive/MyDrive/NCKH_KLTN/Thuc_nghiem/vn_corenlp_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6puytH_Dvj2N",
        "outputId": "3c5ac1b1-3337-4c1a-fde4-4c416b7aa0c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NCKH_KLTN/Vietnamese Car Reviews Dataset/Unlabeled_Data/CSI_phase/Final\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/NCKH_KLTN/Vietnamese Car Reviews Dataset/Unlabeled_Data/CSI_phase/Final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9sW4Ksyvkt0"
      },
      "outputs": [],
      "source": [
        "df125 = pd.read_csv(\"file125_last_update.csv\")\n",
        "df34 = pd.read_csv(\"file34_last_update.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9peWe-sKwvSb"
      },
      "source": [
        "## Nhị phân"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhKjK71AvsTt"
      },
      "outputs": [],
      "source": [
        "df_total =  pd.concat([df125, df34], ignore_index =  True)\n",
        "\n",
        "# 2 labels\n",
        "df_total.loc[df_total[\"CSI\"] == 2, \"CSI\"] = 1   # Comparative sentence là 1, non-comparative sentence là 0\n",
        "df_total.loc[df_total[\"CSI\"] == 3, \"CSI\"] = 1\n",
        "df_total.loc[df_total[\"CSI\"] == 4, \"CSI\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "1b36bxCHvxAl",
        "outputId": "178579b4-3af9-449b-a592-be2485d832b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df_total[\"CSI\"].value_counts().plot.barh()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KGkuCglv0JK"
      },
      "outputs": [],
      "source": [
        "token_main = []\n",
        "for stc in df_total[\"main\"]:\n",
        "    a = rdrsegmenter.word_segment(stc)\n",
        "    assert len(a) == 1, 'Độ dài câu văn khác 1'\n",
        "    token_main.append(a[0])\n",
        "df_total[\"main_token\"] = token_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JTkawvQv9oH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_total.main_token, df_total.CSI, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpHdDBtBws9x"
      },
      "source": [
        "### Using BiLSTM + RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCYeRXbW9rBE"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ0kmZPGu-BT"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTikiYckw_kS"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 6000\n",
        "max_length = 160\n",
        "tokenizer = Tokenizer(num_words = VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkI2jDI8xEw7"
      },
      "outputs": [],
      "source": [
        "train_sequences =  tokenizer.texts_to_sequences(X_train)\n",
        "test_sequences =  tokenizer.texts_to_sequences(X_test)\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVI0uEsdxKW0",
        "outputId": "edd44e75-7a58-4d5f-eede-a61cadf486b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 160)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "padded_train_sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15i1xW9txUpu",
        "outputId": "ef738956-6985-48de-8610-3d79f3bc3b3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4091\n"
          ]
        }
      ],
      "source": [
        "data_vocab_size = len(tokenizer.word_index) + 1\n",
        "print(data_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt3Q14DgxbEb"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcLewStX9uRb"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKm6GOHTxkN5",
        "outputId": "29a763ef-f7e8-42ff-fecc-fe1c4bb13851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/611.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iz7_2o2xcGY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Bidirectional, LSTM, Input, GlobalAveragePooling1D, RNN, GlobalAveragePooling2D, Softmax, SimpleRNN, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2G3rtxT1HZG"
      },
      "outputs": [],
      "source": [
        "# from keras.src import backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGVMwuCpyCv7"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "# INIT_LR = 1e-4\n",
        "# MAX_LR = 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-i-6nFa9ahM"
      },
      "outputs": [],
      "source": [
        "input_dim = data_vocab_size\n",
        "embedding_dim = 4096\n",
        "dropout_threshold = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yHk9dHQyJF6"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Add embedding layer, input_length = max_length\n",
        "model.add(Embedding(input_dim = input_dim, output_dim = embedding_dim))\n",
        "# Add BiLSTM\n",
        "model.add(Bidirectional(LSTM(units=512, dropout = dropout_threshold, return_sequences=False)))\n",
        "\n",
        "# model.add(SimpleRNN(2048))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(2048, activation = 'relu'))\n",
        "# model.add(Dropout(0.3))\n",
        "model.add(Dense(1024, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "adam = Adam(learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDyhrYf74CXn",
        "outputId": "8cea8357-e9e3-48d7-d4ca-1075e4115867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 4096)        16756736  \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 1024)              18878464  \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37242562 (142.07 MB)\n",
            "Trainable params: 37242562 (142.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjsK2Meu1UoF"
      },
      "outputs": [],
      "source": [
        "metrics=[tf.keras.metrics.CategoricalAccuracy(), tfa.metrics.F1Score(num_classes=2, average='macro')]\n",
        "model.compile(optimizer=adam, loss = 'categorical_crossentropy', metrics = metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQjxodPJ83u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a90d1e-4ad6-4a1c-e461-decb9e6783e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 76s 237ms/step - loss: 0.4826 - categorical_accuracy: 0.7807 - f1_score: 0.7802\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 55s 220ms/step - loss: 0.3332 - categorical_accuracy: 0.8691 - f1_score: 0.8689\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 52s 209ms/step - loss: 0.2436 - categorical_accuracy: 0.9021 - f1_score: 0.9020\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 53s 211ms/step - loss: 0.1843 - categorical_accuracy: 0.9275 - f1_score: 0.9274\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 52s 208ms/step - loss: 0.1378 - categorical_accuracy: 0.9470 - f1_score: 0.9469\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 53s 211ms/step - loss: 0.1051 - categorical_accuracy: 0.9594 - f1_score: 0.9593\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 52s 209ms/step - loss: 0.0697 - categorical_accuracy: 0.9746 - f1_score: 0.9746\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 52s 209ms/step - loss: 0.0513 - categorical_accuracy: 0.9837 - f1_score: 0.9837\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 52s 209ms/step - loss: 0.0535 - categorical_accuracy: 0.9846 - f1_score: 0.9846\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 52s 208ms/step - loss: 0.0394 - categorical_accuracy: 0.9889 - f1_score: 0.9889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dc1fffcdf00>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.fit(padded_train_sequences, y_train, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGGV4xvi-SeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33e10b7-e43f-4168-b762-47f97fc8a999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 6s 70ms/step - loss: 0.6918 - categorical_accuracy: 0.8615 - f1_score: 0.8613\n",
            "63/63 [==============================] - 6s 68ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8607    0.8732    0.8669      1033\n",
            "           1     0.8624    0.8490    0.8557       967\n",
            "\n",
            "    accuracy                         0.8615      2000\n",
            "   macro avg     0.8615    0.8611    0.8613      2000\n",
            "weighted avg     0.8615    0.8615    0.8615      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.evaluate(padded_test_sequences, y_test)\n",
        "preds = model.predict(padded_test_sequences)\n",
        "p = tf.math.argmax(preds, 1).numpy()\n",
        "y = tf.math.argmax(y_test, 1).numpy()\n",
        "print(classification_report(y, p, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src import backend\n",
        "class MinimalRNNCell(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, **kwargs):\n",
        "        self.units = units\n",
        "        self.state_size = units\n",
        "        super(MinimalRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "                                      initializer='uniform',\n",
        "                                      name='kernel')\n",
        "        self.recurrent_kernel = self.add_weight(\n",
        "            shape=(self.units, self.units),\n",
        "            initializer='uniform',\n",
        "            name='recurrent_kernel')\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "        h = backend.dot(inputs, self.kernel)\n",
        "        output = h + backend.dot(prev_output, self.recurrent_kernel)\n",
        "        return output, [output]\n",
        "\n",
        "cell = MinimalRNNCell(512)"
      ],
      "metadata": {
        "id": "VuhcZpEhYrMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model = Sequential()\n",
        "\n",
        "# Add embedding layer, input_length = max_length\n",
        "GRU_model.add(Embedding(input_dim = input_dim, output_dim = embedding_dim))\n",
        "# Add BiLSTM\n",
        "GRU_model.add(Bidirectional(GRU(units=512, dropout = dropout_threshold, return_sequences=False)))\n",
        "\n",
        "# GRU_model.add(SimpleRNN(2048))\n",
        "# GRU_model.add(Flatten())\n",
        "# GRU_model.add(Dropout(0.3))\n",
        "# GRU_model.add(Dense(2048, activation = 'relu'))\n",
        "# GRU_model.add(Dropout(0.3))\n",
        "GRU_model.add(Dense(1024, activation = 'relu'))\n",
        "GRU_model.add(Dropout(0.2))\n",
        "GRU_model.add(Dense(512, activation = 'relu'))\n",
        "GRU_model.add(Dropout(0.2))\n",
        "GRU_model.add(Dense(64, activation = 'relu'))\n",
        "GRU_model.add(Dense(2, activation = 'softmax'))\n",
        "\n",
        "adam = Adam(learning_rate = 0.001)"
      ],
      "metadata": {
        "id": "R4RcPD7EVSN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnN7IjC_Vmzl",
        "outputId": "c228a37c-5b9d-4dd0-c8ad-20dcaebf70e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_19 (Embedding)    (None, None, 4096)        16756736  \n",
            "                                                                 \n",
            " bidirectional_17 (Bidirect  (None, 1024)              14161920  \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32526018 (124.08 MB)\n",
            "Trainable params: 32526018 (124.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics=[tf.keras.metrics.CategoricalAccuracy(), tfa.metrics.F1Score(num_classes=2, average='macro')]\n",
        "GRU_model.compile(optimizer=adam, loss = 'categorical_crossentropy', metrics = metrics)"
      ],
      "metadata": {
        "id": "w5pf68XoVrkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.fit(padded_train_sequences, y_train, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-Hmvk8ZV0KM",
        "outputId": "a67ce323-e529-42ba-ffc0-e0539f48736b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 54s 200ms/step - loss: 0.4741 - categorical_accuracy: 0.7835 - f1_score: 0.7828\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 42s 167ms/step - loss: 0.3051 - categorical_accuracy: 0.8754 - f1_score: 0.8752\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 41s 164ms/step - loss: 0.2253 - categorical_accuracy: 0.9128 - f1_score: 0.9127\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 41s 163ms/step - loss: 0.1614 - categorical_accuracy: 0.9373 - f1_score: 0.9372\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 40s 162ms/step - loss: 0.1116 - categorical_accuracy: 0.9590 - f1_score: 0.9589\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 40s 162ms/step - loss: 0.0879 - categorical_accuracy: 0.9676 - f1_score: 0.9676\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 40s 161ms/step - loss: 0.0620 - categorical_accuracy: 0.9781 - f1_score: 0.9781\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 40s 161ms/step - loss: 0.0396 - categorical_accuracy: 0.9865 - f1_score: 0.9865\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 40s 162ms/step - loss: 0.0356 - categorical_accuracy: 0.9881 - f1_score: 0.9881\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 40s 161ms/step - loss: 0.0249 - categorical_accuracy: 0.9914 - f1_score: 0.9914\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7dc19692edd0>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.evaluate(padded_test_sequences, y_test)\n",
        "preds = GRU_model.predict(padded_test_sequences)\n",
        "p = tf.math.argmax(preds, 1).numpy()\n",
        "y = tf.math.argmax(y_test, 1).numpy()\n",
        "print(classification_report(y, p, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTfm6m3PWV2t",
        "outputId": "fbe9657c-fc84-4c75-9293-e51c0d28ccd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 51ms/step - loss: 0.6809 - categorical_accuracy: 0.8525 - f1_score: 0.8517\n",
            "63/63 [==============================] - 4s 48ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8301    0.8984    0.8629      1033\n",
            "           1     0.8810    0.8035    0.8405       967\n",
            "\n",
            "    accuracy                         0.8525      2000\n",
            "   macro avg     0.8555    0.8509    0.8517      2000\n",
            "weighted avg     0.8547    0.8525    0.8520      2000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN46QIkfHOXk+v/A/iSQI/e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}