{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvhieu0163/ComparativeOpinionMining_KLTN2023/blob/main/1_CSI_using_BiLSTM_RNN_GRU_trinary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y6iJv3Wugg_",
        "outputId": "62fff83c-881f-4961-da27-f5ccc4efbc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting py_vncorenlp\n",
            "  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyjnius (from py_vncorenlp)\n",
            "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n",
            "  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4306 sha256=dfcfac5939969baa741e5e68c02e9d7eb8bc3afc6d25aaf3364b5d6077d9b641\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\n",
            "Successfully built py_vncorenlp\n",
            "Installing collected packages: pyjnius, py_vncorenlp\n",
            "Successfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install py_vncorenlp\n",
        "!pip install transformers\n",
        "!pip install tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2yVyoOjvDrj"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjfsRcXdvaG-",
        "outputId": "5c9a6ba0-b2d2-4240-fc92-97191639ae65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsB78z9mvpJY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fom8tvbzvF5y"
      },
      "outputs": [],
      "source": [
        "import py_vncorenlp\n",
        "rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir='/content/drive/MyDrive/NCKH_KLTN/Thuc_nghiem/vn_corenlp_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6puytH_Dvj2N",
        "outputId": "65b4ec14-c4ab-45bd-e056-54ded9e2c28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NCKH_KLTN/Vietnamese Car Reviews Dataset/Unlabeled_Data/CSI_phase/Final\n"
          ]
        }
      ],
      "source": [
        "cd \"/content/drive/MyDrive/NCKH_KLTN/Vietnamese Car Reviews Dataset/Unlabeled_Data/CSI_phase/Final\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9sW4Ksyvkt0"
      },
      "outputs": [],
      "source": [
        "df125 = pd.read_csv(\"file125_last_update.csv\")\n",
        "df34 = pd.read_csv(\"file34_last_update.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9peWe-sKwvSb"
      },
      "source": [
        "## Nhị phân"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhKjK71AvsTt"
      },
      "outputs": [],
      "source": [
        "df_total =  pd.concat([df125, df34], ignore_index =  True)\n",
        "\n",
        "# 3 labels\n",
        "df_total.loc[df_total[\"CSI\"] == 1, \"CSI\"] = 2   # gradable comparative là 2\n",
        "df_total.loc[df_total[\"CSI\"] == 3, \"CSI\"] = 2   # non comparative là 0\n",
        "df_total.loc[df_total[\"CSI\"] == 4, \"CSI\"] = 1   # non gradable comparative là 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "1b36bxCHvxAl",
        "outputId": "4d537a87-7a84-4b39-d25b-be83af7aafaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAVV0lEQVR4nO3df6zVdf3A8dfF6z3A5N4LIRfQi+I0nZKYqHQzzeadRM6y9QdzrDFrNuvSdDhLakn9dVltrnJEbU35K7FaaDOlGApkQ00E9aojLQyWXvBH3HshuyL3/f3DefL6q++l1z2XC4/Hdjbu+bzvfb/Pa/x47txzuHWllBIAAAnGjPQBAIAjh7AAANIICwAgjbAAANIICwAgjbAAANIICwAgjbAAANLU13rDgYGBeOGFF2LChAlRV1dX6+0BgENQSom+vr6YPn16jBnz/s9L1DwsXnjhhWhtba31tgBAgl27dsWJJ574vtdrHhYTJkyIiDcP1tjYWOvtAYBD0NvbG62trdV/x99PzcPirW9/NDY2CgsAGGX+28sYvHgTAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEhTP1Ibz1r2+xhTGT9S20Oq55dfPtJHADgseMYCAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANEMOi02bNsUVV1wR06dPj7q6urjrrruG4VgAwGg05LDYv39/zJ49O1asWDEc5wEARrH6oX7C/PnzY/78+cNxFgBglBtyWAxVf39/9Pf3Vz/u7e0d7i0BgBEy7C/e7OzsjKampuqttbV1uLcEAEbIsIfF0qVLo6enp3rbtWvXcG8JAIyQYf9WSKVSiUqlMtzbAACHAf+PBQCQZsjPWOzbty+ee+656sc7duyIbdu2xaRJk2LGjBmphwMARpchh8Wjjz4an/rUp6ofL1myJCIiFi1aFKtWrUo7GAAw+gw5LC655JIopQzHWQCAUc5rLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEgjLACANMICAEhTP1Ibd31vXjQ2No7U9gDAMPCMBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQpn6kNp617PcxpjJ+pLYHRsDzyy8f6SMAw8wzFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAGmEBAKQRFgBAmiGFRWdnZ5x//vkxYcKEmDJlSlx55ZWxffv24TobADDKDCksNm7cGB0dHfHQQw/FunXr4sCBA3HZZZfF/v37h+t8AMAoUj+UxWvXrh308apVq2LKlCmxZcuWuPjii1MPBgCMPkMKi3fq6emJiIhJkya975r+/v7o7++vftzb2/u/bAkAHMYO+cWbAwMDcf3118eFF14Ys2bNet91nZ2d0dTUVL21trYe6pYAwGHukMOio6Mjurq6YvXq1R+4bunSpdHT01O97dq161C3BAAOc4f0rZDFixfHPffcE5s2bYoTTzzxA9dWKpWoVCqHdDgAYHQZUliUUuLrX/96rFmzJjZs2BAzZ84crnMBAKPQkMKio6MjfvGLX8Tdd98dEyZMiO7u7oiIaGpqinHjxg3LAQGA0WNIr7FYuXJl9PT0xCWXXBLTpk2r3u68887hOh8AMIoM+VshAADvx88KAQDSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAIE39SG3c9b150djYOFLbAwDDwDMWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAEAaYQEApBEWAECa+pHaeNay38eYyviR2h4AjjjPL798pI/gGQsAII+wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSHFJYrFixIk4++eQYO3ZszJ07Nx555JHscwEAo9CQw+LOO++MJUuWxLJly+Kxxx6L2bNnx7x582LPnj3DcT4AYBQZcljccsstcc0118TVV18dZ555Zvz0pz+N8ePHx2233TYc5wMARpEhhcXrr78eW7Zsifb29v98gTFjor29PTZv3vyen9Pf3x+9vb2DbgDAkWlIYfHyyy/HwYMHo6WlZdD9LS0t0d3d/Z6f09nZGU1NTdVba2vroZ8WADisDfu7QpYuXRo9PT3V265du4Z7SwBghNQPZfHkyZPjmGOOid27dw+6f/fu3TF16tT3/JxKpRKVSuXQTwgAjBpDesaioaEh5syZE+vXr6/eNzAwEOvXr4+2trb0wwEAo8uQnrGIiFiyZEksWrQozjvvvLjgggvihz/8Yezfvz+uvvrq4TgfADCKDDksFixYEC+99FLcfPPN0d3dHeecc06sXbv2XS/oBACOPkMOi4iIxYsXx+LFi7PPAgCMcn5WCACQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQRlgAAGmEBQCQpn6kNu763rxobGwcqe0BgGHgGQsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAII2wAADSCAsAIE19rTcspURERG9vb623BgAO0Vv/br/17/j7qXlYvPLKKxER0draWuutAYD/UV9fXzQ1Nb3v9ZqHxaRJkyIiYufOnR94MP43vb290draGrt27YrGxsaRPs4Rzaxrx6xrx6xrZ7TMupQSfX19MX369A9cV/OwGDPmzZd1NDU1HdYDPFI0Njaac42Yde2Yde2Yde2Mhln/f54Q8OJNACCNsAAA0tQ8LCqVSixbtiwqlUqttz6qmHPtmHXtmHXtmHXtHGmzriv/7X0jAAD/T74VAgCkERYAQBphAQCkERYAQJqahsWKFSvi5JNPjrFjx8bcuXPjkUceqeX2o86mTZviiiuuiOnTp0ddXV3cddddg66XUuLmm2+OadOmxbhx46K9vT2effbZQWteffXVWLhwYTQ2NkZzc3N8+ctfjn379g1a88QTT8RFF10UY8eOjdbW1vj+978/3A/tsNPZ2Rnnn39+TJgwIaZMmRJXXnllbN++fdCaf//739HR0REf+tCH4rjjjosvfOELsXv37kFrdu7cGZdffnmMHz8+pkyZEjfeeGO88cYbg9Zs2LAhzj333KhUKnHqqafGqlWrhvvhHVZWrlwZZ599dvU/A2pra4v77ruvet2ch8fy5cujrq4urr/++up9Zp3nu9/9btTV1Q26nXHGGdXrR9WsS42sXr26NDQ0lNtuu6089dRT5ZprrinNzc1l9+7dtTrCqHPvvfeWb3/72+U3v/lNiYiyZs2aQdeXL19empqayl133VUef/zx8tnPfrbMnDmzvPbaa9U1n/70p8vs2bPLQw89VP74xz+WU089tVx11VXV6z09PaWlpaUsXLiwdHV1lTvuuKOMGzeu/OxnP6vVwzwszJs3r9x+++2lq6urbNu2rXzmM58pM2bMKPv27auuufbaa0tra2tZv359efTRR8vHPvax8vGPf7x6/Y033iizZs0q7e3tZevWreXee+8tkydPLkuXLq2u+dvf/lbGjx9flixZUp5++uly6623lmOOOaasXbu2po93JP32t78tv/vd78pf/vKXsn379vKtb32rHHvssaWrq6uUYs7D4ZFHHiknn3xyOfvss8t1111Xvd+s8yxbtqycddZZ5cUXX6zeXnrpper1o2nWNQuLCy64oHR0dFQ/PnjwYJk+fXrp7Oys1RFGtXeGxcDAQJk6dWr5wQ9+UL1v7969pVKplDvuuKOUUsrTTz9dIqL8+c9/rq657777Sl1dXfnHP/5RSinlJz/5SZk4cWLp7++vrvnmN79ZTj/99GF+RIe3PXv2lIgoGzduLKW8Odtjjz22/OpXv6queeaZZ0pElM2bN5dS3gzBMWPGlO7u7uqalStXlsbGxup8v/GNb5Szzjpr0F4LFiwo8+bNG+6HdFibOHFi+fnPf27Ow6Cvr6+cdtppZd26deWTn/xkNSzMOteyZcvK7Nmz3/Pa0Tbrmnwr5PXXX48tW7ZEe3t79b4xY8ZEe3t7bN68uRZHOOLs2LEjuru7B820qakp5s6dW53p5s2bo7m5Oc4777zqmvb29hgzZkw8/PDD1TUXX3xxNDQ0VNfMmzcvtm/fHv/85z9r9GgOPz09PRHxnx+at2XLljhw4MCgeZ9xxhkxY8aMQfP+yEc+Ei0tLdU18+bNi97e3njqqaeqa97+Nd5ac7T+OTh48GCsXr069u/fH21tbeY8DDo6OuLyyy9/1zzMOt+zzz4b06dPj1NOOSUWLlwYO3fujIijb9Y1CYuXX345Dh48OGhgEREtLS3R3d1diyMccd6a2wfNtLu7O6ZMmTLoen19fUyaNGnQmvf6Gm/f42gzMDAQ119/fVx44YUxa9asiHhzFg0NDdHc3Dxo7Tvn/d9m+X5rent747XXXhuOh3NYevLJJ+O4446LSqUS1157baxZsybOPPNMc062evXqeOyxx6Kzs/Nd18w619y5c2PVqlWxdu3aWLlyZezYsSMuuuii6OvrO+pmXfOfbgqHu46Ojujq6ooHH3xwpI9yxDr99NNj27Zt0dPTE7/+9a9j0aJFsXHjxpE+1hFl165dcd1118W6deti7NixI32cI978+fOrvz777LNj7ty5cdJJJ8Uvf/nLGDdu3AierPZq8ozF5MmT45hjjnnXK2B3794dU6dOrcURjjhvze2DZjp16tTYs2fPoOtvvPFGvPrqq4PWvNfXePseR5PFixfHPffcEw888ECceOKJ1funTp0ar7/+euzdu3fQ+nfO+7/N8v3WNDY2HlV/+TQ0NMSpp54ac+bMic7Ozpg9e3b86Ec/MudEW7ZsiT179sS5554b9fX1UV9fHxs3bowf//jHUV9fHy0tLWY9jJqbm+PDH/5wPPfcc0fd7+uahEVDQ0PMmTMn1q9fX71vYGAg1q9fH21tbbU4whFn5syZMXXq1EEz7e3tjYcffrg607a2tti7d29s2bKluub++++PgYGBmDt3bnXNpk2b4sCBA9U169ati9NPPz0mTpxYo0cz8kopsXjx4lizZk3cf//9MXPmzEHX58yZE8cee+ygeW/fvj127tw5aN5PPvnkoJhbt25dNDY2xplnnlld8/av8daao/3PwcDAQPT395tzoksvvTSefPLJ2LZtW/V23nnnxcKFC6u/Nuvhs2/fvvjrX/8a06ZNO/p+X9fqVaKrV68ulUqlrFq1qjz99NPlK1/5Smlubh70ClgG6+vrK1u3bi1bt24tEVFuueWWsnXr1vL3v/+9lPLm202bm5vL3XffXZ544onyuc997j3fbvrRj360PPzww+XBBx8sp5122qC3m+7du7e0tLSUL37xi6Wrq6usXr26jB8//qh7u+lXv/rV0tTUVDZs2DDo7WL/+te/qmuuvfbaMmPGjHL//feXRx99tLS1tZW2trbq9bfeLnbZZZeVbdu2lbVr15bjjz/+Pd8uduONN5ZnnnmmrFix4rB8u9hwuummm8rGjRvLjh07yhNPPFFuuummUldXV/7whz+UUsx5OL39XSGlmHWmG264oWzYsKHs2LGj/OlPfyrt7e1l8uTJZc+ePaWUo2vWNQuLUkq59dZby4wZM0pDQ0O54IILykMPPVTL7UedBx54oETEu26LFi0qpbz5ltPvfOc7paWlpVQqlXLppZeW7du3D/oar7zySrnqqqvKcccdVxobG8vVV19d+vr6Bq15/PHHyyc+8YlSqVTKCSecUJYvX16rh3jYeK85R0S5/fbbq2tee+218rWvfa1MnDixjB8/vnz+858vL7744qCv8/zzz5f58+eXcePGlcmTJ5cbbrihHDhwYNCaBx54oJxzzjmloaGhnHLKKYP2OBp86UtfKieddFJpaGgoxx9/fLn00kurUVGKOQ+nd4aFWedZsGBBmTZtWmloaCgnnHBCWbBgQXnuueeq14+mWfux6QBAGj8rBABIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDTCAgBIIywAgDT/B7BDtaLMgEWCAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df_total[\"CSI\"].value_counts().plot.barh()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KGkuCglv0JK"
      },
      "outputs": [],
      "source": [
        "token_main = []\n",
        "for stc in df_total[\"main\"]:\n",
        "    a = rdrsegmenter.word_segment(stc)\n",
        "    assert len(a) == 1, 'Độ dài câu văn khác 1'\n",
        "    token_main.append(a[0])\n",
        "df_total[\"main_token\"] = token_main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JTkawvQv9oH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_total.main_token, df_total.CSI, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpHdDBtBws9x"
      },
      "source": [
        "### Using BiLSTM + RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCYeRXbW9rBE"
      },
      "source": [
        "Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJ0kmZPGu-BT"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTikiYckw_kS"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 6000\n",
        "max_length = 160\n",
        "tokenizer = Tokenizer(num_words = VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkI2jDI8xEw7"
      },
      "outputs": [],
      "source": [
        "train_sequences =  tokenizer.texts_to_sequences(X_train)\n",
        "test_sequences =  tokenizer.texts_to_sequences(X_test)\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen=max_length, truncating=\"post\", padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVI0uEsdxKW0",
        "outputId": "45d3cf05-e934-45fc-d4c5-952c1423bb08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 160)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "padded_train_sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15i1xW9txUpu",
        "outputId": "3ece351a-6960-46ec-fd4a-337f45815bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4091\n"
          ]
        }
      ],
      "source": [
        "data_vocab_size = len(tokenizer.word_index) + 1\n",
        "print(data_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt3Q14DgxbEb"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC-QedNDCVcz",
        "outputId": "633855df-c866-4954-daf0-80f703e602f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcLewStX9uRb"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKm6GOHTxkN5",
        "outputId": "ed70b600-b545-4aca-98d1-13d7448b23e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Using cached tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iz7_2o2xcGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92218c73-4a82-48a3-9e69-a397d0ec25c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, Bidirectional, LSTM, Input, GlobalAveragePooling1D, RNN, GlobalAveragePooling2D, Softmax, SimpleRNN, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2G3rtxT1HZG"
      },
      "outputs": [],
      "source": [
        "# from keras.src import backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGVMwuCpyCv7"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "# INIT_LR = 1e-4\n",
        "# MAX_LR = 1e-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-i-6nFa9ahM"
      },
      "outputs": [],
      "source": [
        "input_dim = data_vocab_size\n",
        "embedding_dim = 4096\n",
        "dropout_threshold = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yHk9dHQyJF6"
      },
      "outputs": [],
      "source": [
        "LSTM_model = Sequential()\n",
        "\n",
        "# Add embedding layer, input_length = max_length\n",
        "LSTM_model.add(Embedding(input_dim = input_dim, output_dim = 4096))\n",
        "# Add BiLSTM\n",
        "LSTM_model.add(Bidirectional(LSTM(units=512, dropout = dropout_threshold, return_sequences=False)))\n",
        "\n",
        "# LSTM_model.add(SimpleRNN(2048))\n",
        "# LSTM_model.add(Flatten())\n",
        "# LSTM_model.add(Dropout(0.3))\n",
        "# LSTM_model.add(Dense(2048, activation = 'relu'))\n",
        "# LSTM_model.add(Dropout(0.3))\n",
        "LSTM_model.add(Dense(1024, activation = 'relu'))\n",
        "LSTM_model.add(Dropout(0.2))\n",
        "LSTM_model.add(Dense(512, activation = 'relu'))\n",
        "LSTM_model.add(Dropout(0.2))\n",
        "LSTM_model.add(Dense(64, activation = 'relu'))\n",
        "LSTM_model.add(Dense(3, activation = 'softmax'))\n",
        "\n",
        "adam = Adam(learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDyhrYf74CXn",
        "outputId": "5fb60eb8-cb45-48b6-be97-7926aea108bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, None, 4096)        16756736  \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirecti  (None, 1024)              18878464  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37242627 (142.07 MB)\n",
            "Trainable params: 37242627 (142.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LSTM_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjsK2Meu1UoF"
      },
      "outputs": [],
      "source": [
        "metrics=[tf.keras.metrics.CategoricalAccuracy(), tfa.metrics.F1Score(num_classes=3, average='macro')]\n",
        "LSTM_model.compile(optimizer=adam, loss = 'categorical_crossentropy', metrics = metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQjxodPJ83u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759d1ef3-ebcb-454f-c145-9ed1e291c897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 61s 229ms/step - loss: 0.7319 - categorical_accuracy: 0.7038 - f1_score: 0.6516\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 49s 196ms/step - loss: 0.5168 - categorical_accuracy: 0.8086 - f1_score: 0.7748\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 48s 192ms/step - loss: 0.3879 - categorical_accuracy: 0.8571 - f1_score: 0.8312\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 47s 189ms/step - loss: 0.3008 - categorical_accuracy: 0.8878 - f1_score: 0.8654\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 47s 189ms/step - loss: 0.2289 - categorical_accuracy: 0.9166 - f1_score: 0.8994\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 47s 190ms/step - loss: 0.1768 - categorical_accuracy: 0.9376 - f1_score: 0.9255\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 47s 189ms/step - loss: 0.1299 - categorical_accuracy: 0.9556 - f1_score: 0.9464\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 48s 191ms/step - loss: 0.1033 - categorical_accuracy: 0.9660 - f1_score: 0.9608\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 47s 188ms/step - loss: 0.0819 - categorical_accuracy: 0.9734 - f1_score: 0.9684\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 47s 188ms/step - loss: 0.0610 - categorical_accuracy: 0.9810 - f1_score: 0.9774\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a00d913abc0>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "LSTM_model.fit(padded_train_sequences, y_train, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGGV4xvi-SeL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59901398-aa24-4e18-df0d-e60d4d2c6406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 5s 64ms/step - loss: 1.0046 - categorical_accuracy: 0.8050 - f1_score: 0.7734\n",
            "63/63 [==============================] - 4s 61ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8623    0.8790    0.8706      1033\n",
            "           1     0.6442    0.7053    0.6734       380\n",
            "           2     0.8173    0.7394    0.7764       587\n",
            "\n",
            "    accuracy                         0.8050      2000\n",
            "   macro avg     0.7746    0.7745    0.7734      2000\n",
            "weighted avg     0.8077    0.8050    0.8055      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LSTM_model.evaluate(padded_test_sequences, y_test)\n",
        "preds = LSTM_model.predict(padded_test_sequences)\n",
        "p = tf.math.argmax(preds, 1).numpy()\n",
        "y = tf.math.argmax(y_test, 1).numpy()\n",
        "print(classification_report(y, p, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.src import backend\n",
        "# class MinimalRNNCell(keras.layers.Layer):\n",
        "\n",
        "#     def __init__(self, units, **kwargs):\n",
        "#         self.units = units\n",
        "#         self.state_size = units\n",
        "#         super(MinimalRNNCell, self).__init__(**kwargs)\n",
        "\n",
        "#     def build(self, input_shape):\n",
        "#         self.kernel = self.add_weight(shape=(input_shape[-1], self.units),\n",
        "#                                       initializer='uniform',\n",
        "#                                       name='kernel')\n",
        "#         self.recurrent_kernel = self.add_weight(\n",
        "#             shape=(self.units, self.units),\n",
        "#             initializer='uniform',\n",
        "#             name='recurrent_kernel')\n",
        "#         self.built = True\n",
        "\n",
        "#     def call(self, inputs, states):\n",
        "#         prev_output = states[0]\n",
        "#         h = backend.dot(inputs, self.kernel)\n",
        "#         output = h + backend.dot(prev_output, self.recurrent_kernel)\n",
        "#         return output, [output]\n",
        "\n",
        "# cell = MinimalRNNCell(512)"
      ],
      "metadata": {
        "id": "VuhcZpEhYrMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model = Sequential()\n",
        "\n",
        "# Add embedding layer, input_length = max_length\n",
        "GRU_model.add(Embedding(input_dim = input_dim, output_dim = 4096))\n",
        "# Add BiLSTM\n",
        "GRU_model.add(Bidirectional(GRU(units=512, dropout = dropout_threshold, return_sequences=False)))\n",
        "\n",
        "# GRU_model.add(SimpleRNN(2048))\n",
        "# GRU_model.add(Flatten())\n",
        "# GRU_model.add(Dropout(0.3))\n",
        "# GRU_model.add(Dense(2048, activation = 'relu'))\n",
        "# GRU_model.add(Dropout(0.3))\n",
        "GRU_model.add(Dense(1024, activation = 'relu'))\n",
        "GRU_model.add(Dropout(0.2))\n",
        "GRU_model.add(Dense(512, activation = 'relu'))\n",
        "GRU_model.add(Dropout(0.2))\n",
        "GRU_model.add(Dense(64, activation = 'relu'))\n",
        "GRU_model.add(Dense(3, activation = 'softmax'))\n",
        "\n",
        "adam = Adam(learning_rate = 0.0001)"
      ],
      "metadata": {
        "id": "R4RcPD7EVSN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnN7IjC_Vmzl",
        "outputId": "4857b635-a059-4275-d0f2-3c6739b87309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, None, 4096)        16756736  \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 1024)              14161920  \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32526083 (124.08 MB)\n",
            "Trainable params: 32526083 (124.08 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics=[tf.keras.metrics.CategoricalAccuracy(), tfa.metrics.F1Score(num_classes=3, average='macro')]\n",
        "GRU_model.compile(optimizer=adam, loss = 'categorical_crossentropy', metrics = metrics)"
      ],
      "metadata": {
        "id": "w5pf68XoVrkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.fit(padded_train_sequences, y_train, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-Hmvk8ZV0KM",
        "outputId": "0d0fe423-2270-474b-dc51-b21ff7cacc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 52s 186ms/step - loss: 0.8354 - categorical_accuracy: 0.6280 - f1_score: 0.5226\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 38s 153ms/step - loss: 0.5459 - categorical_accuracy: 0.7899 - f1_score: 0.7496\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 38s 152ms/step - loss: 0.4562 - categorical_accuracy: 0.8244 - f1_score: 0.7917\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 37s 147ms/step - loss: 0.3960 - categorical_accuracy: 0.8510 - f1_score: 0.8244\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 37s 147ms/step - loss: 0.3423 - categorical_accuracy: 0.8740 - f1_score: 0.8518\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 37s 146ms/step - loss: 0.3174 - categorical_accuracy: 0.8813 - f1_score: 0.8598\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 36s 144ms/step - loss: 0.2851 - categorical_accuracy: 0.8923 - f1_score: 0.8724\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 37s 146ms/step - loss: 0.2529 - categorical_accuracy: 0.9085 - f1_score: 0.8914\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 36s 144ms/step - loss: 0.2228 - categorical_accuracy: 0.9224 - f1_score: 0.9084\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 36s 144ms/step - loss: 0.1965 - categorical_accuracy: 0.9269 - f1_score: 0.9136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a00dbc42890>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GRU_model.evaluate(padded_test_sequences, y_test)\n",
        "preds = GRU_model.predict(padded_test_sequences)\n",
        "p = tf.math.argmax(preds, 1).numpy()\n",
        "y = tf.math.argmax(y_test, 1).numpy()\n",
        "print(classification_report(y, p, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTfm6m3PWV2t",
        "outputId": "2bf46687-7228-4144-df7c-f6df75d8fd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 47ms/step - loss: 0.7311 - categorical_accuracy: 0.7925 - f1_score: 0.7594\n",
            "63/63 [==============================] - 3s 44ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8526    0.8732    0.8627      1033\n",
            "           1     0.6491    0.6816    0.6650       380\n",
            "           2     0.7808    0.7223    0.7504       587\n",
            "\n",
            "    accuracy                         0.7925      2000\n",
            "   macro avg     0.7608    0.7590    0.7594      2000\n",
            "weighted avg     0.7929    0.7925    0.7922      2000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNg/SnPAiEHb3fwds2si2TC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}